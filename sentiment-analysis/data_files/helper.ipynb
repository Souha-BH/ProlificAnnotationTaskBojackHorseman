{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a094193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 'id' column and saved to reddit_posts_with_id.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"reddit_posts.csv\")\n",
    "\n",
    "# Add an ID column starting from 1\n",
    "df.insert(0, \"id\", range(1, len(df) + 1))\n",
    "\n",
    "# Save it back to the same file (or a new one if you want to keep the original)\n",
    "df.to_csv(\"reddit_posts_with_id.csv\", index=False)\n",
    "\n",
    "print(\"✅ Added 'id' column and saved to reddit_posts_with_id.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa17ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 'context' column for Potato display.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file with id column\n",
    "df = pd.read_csv(\"reddit_posts_with_id.csv\")\n",
    "\n",
    "# Create a context column for Potato\n",
    "df[\"context\"] = df.apply(\n",
    "    lambda row: f'What is the sentiment towards **{row[\"character_name\"]}** from *{row[\"series_name\"]}* in this post?',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save new file\n",
    "df.to_csv(\"reddit_posts_with_context.csv\", index=False)\n",
    "\n",
    "print(\"✅ Added 'context' column for Potato display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00d2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"reddit_posts_with_context.csv\")\n",
    "df[\"full_text\"] = (\n",
    "    \"Character: \" + df[\"character_name\"] +\n",
    "    \" | Series: \" + df[\"series_name\"] +\n",
    "    \"\\n\\n\" +\n",
    "    \"\\n\\n\"+\n",
    "    df[\"post_text\"]\n",
    ")\n",
    "df.to_csv(\"reddit_posts_with_context.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fd9de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords.tsv saved with 66 entries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- Config ----\n",
    "csv_file = \"reddit_posts_with_context.csv\"  # your CSV file\n",
    "character_col = \"character_name\"\n",
    "series_col = \"series_name\"\n",
    "output_tsv = \"keywords.tsv\"\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=[character_col, series_col])\n",
    "\n",
    "# Assign label per series\n",
    "series_to_label = {}\n",
    "labels = []\n",
    "for series in df[series_col].unique():\n",
    "    series_to_label[series] = f\"color_{len(series_to_label) + 1}\"\n",
    "\n",
    "# Build TSV rows\n",
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    word = row[character_col]\n",
    "    label = series_to_label[row[series_col]]\n",
    "    schema = \"highlight\"  # You can name this the same as your Potato schema if needed\n",
    "    rows.append((word, label, schema))\n",
    "\n",
    "# Create DataFrame\n",
    "tsv_df = pd.DataFrame(rows, columns=[\"Word\", \"Label\", \"Schema\"])\n",
    "\n",
    "# Save TSV\n",
    "tsv_df.to_csv(output_tsv, sep=\"\\t\", index=False)\n",
    "print(f\"keywords.tsv saved with {len(tsv_df)} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c37bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_csv, output_json):\n",
    "    data = []\n",
    "    \n",
    "    with open(input_csv, mode='r', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        for row in reader:\n",
    "            series_name = row['series_name']\n",
    "            character_name = row['character_name']\n",
    "            post_text = row['post_text']\n",
    "            \n",
    "            # Create formatted text\n",
    "            series_text = f\"<strong>Series: </strong>{series_name}\"\n",
    "            character_text = f\"<strong>Character: </strong>{character_name}\"\n",
    "            post_text_formatted = f\"<strong>Post: </strong>{post_text.strip()}\"\n",
    "            \n",
    "            # Add to data list\n",
    "            data.append({\n",
    "                \"id\": row['id'],\n",
    "                \"text\": [series_text, character_text, post_text_formatted]\n",
    "            })\n",
    "    \n",
    "    # Write to JSON file (one object per line)\n",
    "    with open(output_json, mode='w', encoding='utf-8') as json_file:\n",
    "        for entry in data:\n",
    "            json_file.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "csv_to_json(\"reddit_posts_with_context.csv\", \"output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896a4c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output_series_files/BoJackHorseman_potato_first_round.csv\n",
      "Saved: output_series_files/BridgertonNetflix_potato_first_round.csv\n",
      "Saved: output_series_files/Daredevil_potato_first_round.csv\n",
      "Saved: output_series_files/EmilyInParis_potato_first_round.csv\n",
      "Saved: output_series_files/FromSeries_potato_first_round.csv\n",
      "Saved: output_series_files/HouseOfTheDragon_potato_first_round.csv\n",
      "Saved: output_series_files/Invincible_potato_first_round.csv\n",
      "Saved: output_series_files/LOTR_on_Prime_potato_first_round.csv\n",
      "Saved: output_series_files/MrRobot_potato_first_round.csv\n",
      "Saved: output_series_files/PeakyBlinders_potato_first_round.csv\n",
      "Saved: output_series_files/SeveranceAppleTVPlus_potato_first_round.csv\n",
      "Saved: output_series_files/StrangerThings_potato_first_round.csv\n",
      "Saved: output_series_files/SuccessionTV_potato_first_round.csv\n",
      "Saved: output_series_files/TheBoys_potato_first_round.csv\n",
      "Saved: output_series_files/Yellowjackets_potato_first_round.csv\n",
      "Saved: output_series_files/YouOnLifetime_potato_first_round.csv\n",
      "Saved: output_series_files/arcane_potato_first_round.csv\n",
      "Saved: output_series_files/betterCallSaul_potato_first_round.csv\n",
      "Saved: output_series_files/cobrakai_potato_first_round.csv\n",
      "Saved: output_series_files/euphoria_potato_first_round.csv\n",
      "Saved: output_series_files/gameofthrones_potato_first_round.csv\n",
      "Saved: output_series_files/lucifer_potato_first_round.csv\n",
      "Saved: output_series_files/squidgame_potato_first_round.csv\n",
      "Saved: output_series_files/thewalkingdead_potato_first_round.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_and_expand_csv(input_csv, output_dir):\n",
    "    # Read the input CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Group by series_name\n",
    "    for series, group in df.groupby('series_name'):\n",
    "        expanded_rows = []\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            characters = [char.strip() for char in str(row['character_names_4o_p3']).split(',')]\n",
    "            \n",
    "            for character in characters:\n",
    "                new_row = row.to_dict()\n",
    "                new_row['character_name'] = character  # Add new column\n",
    "                expanded_rows.append(new_row)\n",
    "        \n",
    "        # Create DataFrame for this series\n",
    "        expanded_df = pd.DataFrame(expanded_rows)\n",
    "        \n",
    "        # Save file as \"<series_name>_potato_first_round.csv\"\n",
    "        file_name = f\"{series}_potato_first_round.csv\".replace(\" \", \"_\")\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        expanded_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "split_and_expand_csv(\"AllRelevantPostsFromAllSeries.csv\", \"output_series_files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2accb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_csv, output_json):\n",
    "    data = []\n",
    "    \n",
    "    with open(input_csv, mode='r', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        for row in reader:\n",
    "            series_name = row['series']\n",
    "            character_name = row['character_to_annotate']\n",
    "            post_text = row['title'] + \"\\n\\n\" + row['selftext']\n",
    "            character_link = row.get('Link to character', '').strip()  # Get link if exists\n",
    "            \n",
    "            # Create formatted text\n",
    "            series_text = f\"<strong>Series: </strong>{series_name}\"\n",
    "            \n",
    "            # Add link to character name if available\n",
    "            if character_link:\n",
    "                character_text = f'<strong>Character: </strong><a href=\"{character_link}\" target=\"_blank\">{character_name}</a>'\n",
    "            else:\n",
    "                character_text = f\"<strong>Character: </strong>{character_name}\"\n",
    "            \n",
    "            post_text_formatted = f\"<strong>Post: </strong>{post_text.strip()}\"\n",
    "            \n",
    "            # Add to data list\n",
    "            data.append({\n",
    "                \"id\": row['id'],\n",
    "                \"text\": [series_text, character_text, post_text_formatted]\n",
    "            })\n",
    "    \n",
    "    # Write to JSON file (one object per line)\n",
    "    with open(output_json, mode='w', encoding='utf-8') as json_file:\n",
    "        for entry in data:\n",
    "            json_file.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "csv_to_json(\"reddit_posts_with_context_with_single_links.csv\", \"testingfandomlinks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38eba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json(\"ProlificBoJackHorseman.csv\", \"ProlificBoJackHorseman.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b84a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
